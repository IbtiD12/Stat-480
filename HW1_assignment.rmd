---
title: "Homework 1 Assignment"
author: "Ibtisaam Dalvi"
fontsize: 10 pt
output:
  pdf_document:
    fig_width: 6
    fig_height: 4
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      #include = TRUE, 
                      fig.width = 6, fig.height = 4,
                      #results='hide',
                      warning = FALSE,
                      cache = TRUE,
                      digits = 3,
                      width = 48) 

```

# Amazon Reviews

The dataset consists of 13 319 reviews for selected products on Amazon from Jan-Oct 2012.  Reviews include product information, ratings, and a plain text review. 

We will look for words associated with good/bad ratings.


The data consists of three tables:

## Review subset.csv
is a table containing, for each review, its

\begin{itemize}
\item ProductId: Amazon ASIN product code
\item UserId: ID of the reviewer
\item Score: numeric 1-5 (the number of stars)
\item Time: date of the review
\item Summary: review summary in words
\item Nrev: number of reviews by the user
\item Length: number of words in the review
\item Prod Category: Amazon product category 
\item Prod Group: Amazon product group
\end{itemize}

## Word freq.csv
is a simple triplet matrix of word counts from the review text including 
\begin{itemize}
\item Review ID: the row index of Review subset.csv
\item Word ID: the row index of words.csv
\item Times Word: how many times the word occurred in the review
\end{itemize}

## Words.csv
contains 1125 alphabetically ordered words that occur in the reviews. 

\clearpage


## Data exploration

The code below loads the data.

```{r data xtable, results='asis'}


library(knitr) # library for nice R markdown output


# READ REVIEWS

data<-read.table("Review_subset.csv",header=TRUE)
dim(data)

# 13319 reviews
# ProductID: Amazon ASIN product code
# UserID:  id of the reviewer
# Score: numeric from 1 to 5
# Time: date of the review
# Summary: text review
# nrev: number of reviews by this user
# Length: length of the review (number of words)

# READ WORDS

words<-read.table("words.csv")
words<-words[,1]
length(words)
#1125 unique words


# READ text-word pairings file

doc_word<-read.table("word_freq.csv")
names(doc_word)<-c("Review ID","Word ID","Times Word" )
# Review ID: row of the file  Review_subset
# Word ID: index of the word
# Times Word: number of times this word occurred in the text
View(doc_word)



```

## Marginal Regression Screening

We would like to pre-screen words that associate with ratings. To this end,  we run a series of (independent)
marginal regressions  of review Score on word presence  in review text for each of  1125 words. 

In the starter script below, you  will find a code to run these marginal regressions (both in parallel and sequentially). The code gives you a set of p-values for a marginal effect of each word. That is, we fit
$$
{\tt stars}_i = \alpha + \beta_j I{[x_{ji}>0]} + \epsilon_{ji}
$$
for each word term $j$ with count $x_{ji}$ in review $i$, and return the p-value associated with a test of $\beta_{j}\neq0$. We'll use these 1125 independent regressions to screen words.


```{r data, results='asis'}

# We'll do 1125 univariate regressions of 
# star rating on word presence, one for each word.
# Each regression will return a p-value, and we can
# use this as an initial screen for useful words.

# Don't worry if you do not understand the code now.
# We will go over similar code in  the class in a few weeks.

# Create a sparse matrix of word presence


library(gamlr)

spm<-sparseMatrix(i=doc_word[,1],
                  j=doc_word[,2],
                  x=doc_word[,3],
                  dimnames=list(id=1:nrow(data),words=words))

dim(spm)
# 13319 reviews using 1125 words

# Create a dense matrix of word presence

P <- as.data.frame(as.matrix(spm>0))

library(parallel)

margreg <- function(p){
	fit <- lm(stars~p)
	sf <- summary(fit)
	return(sf$coef[2,4]) 
}

# The code below is an example of parallel computing
# No need to understand details now, we will discuss more later

cl <- makeCluster(detectCores())

# Pull out stars and export to cores

stars <- data$Score

clusterExport(cl,"stars") 

# Run the regressions in parallel

mrgpvals <- unlist(parLapply(cl,P,margreg))

# If parallel stuff is not working, 
# you can also just do (in serial):
# mrgpvals <- c()
# for(j in 1:1125){
# 	print(j)
# 	mrgpvals <- c(mrgpvals,margreg(P[,j]))
# }
# make sure we have names

names(mrgpvals) <- colnames(P)

# The p-values are stored in mrgpvals 


```



## Homework Questions:

### (1) Plot the p-values from the marginal screening and comment on their distribution.
(10 point)
```{r}
hist(mrgpvals,col="chocolate",breaks=10)
```

The distribution of p-values does not follow a Uniform(0, 1) distribution and shows a high concentration at the lower end of the range, which indicates some potential evidence for the alternative hypothesis. 

### (2) Let's do standard statistical testing. How many tests are significant at the alpha level 0.05 and 0.01?
(10 point)
```{r}
sum(mrgpvals < 0.05)
sum(mrgpvals < 0.01)
```
461 tests are significant at the 0.05 level.
348 tests are significant at the 0.01 level.

### (3) What is the p-value cutoff for 1% FDR? Plot and describe the rejection region.
(10 point)
```{r}
fdr_cut <- function(pvals, q, plotit=TRUE, ...){
	
  pvals = pvals[!is.na(pvals)]
  N = length(pvals)
  k = rank(pvals, ties.method="min")
  alpha = max(pvals[ pvals <= (q*k/N) ])
  
  if(plotit){
    sig = factor(pvals<=alpha)
    o = order(pvals)
    plot(pvals[o], col=c("grey60","red")[sig[o]], pch=20,
       ylab = "p-values", xlab = "tests ordered by p-value", 
       main = paste('FDR =', q), ylim = c(0, 0.051))
       abline(h = alpha, lty=2,col=3,lwd=3)
  }
  return(alpha)
}

cutoff = fdr_cut(mrgpvals, 0.01)
cutoff
```

The p-value cutoff is about 0.002413249. The green dashed line in the plot represents this cutoff, which is the boundary of our rejection region. Any p-values below this line can be considered significant at the new cutoff $\alpha$*.


### (4) How many discoveries do you find at q=0.01 and how many do you expect to be false?
(10 point)
```{r}
(disc = unname(table(mrgpvals<=cutoff)[2]))
(fd = disc * 0.01)
```

At q = 0.01, we made 290 discoveries and we would expect 1% of those to be false, which is equivalent to about 3 false discoveries.


### (5) What are the 10 most significant words? Do these results make sense to you? What are the advantages and disadvantages of our FDR anaysis?
(10 point)
```{r}
names(head(sort(mrgpvals), n = 10))
```

The top 10 significant words determined by FDR analysis predominantly consist of emotionally charged adjectives. This aligns with the typical content of product reviews, where customers often express their sentiments. Notably, the majority of these significant words convey negative sentiments, reflecting the common tendency of customers to leave reviews when they are dissatisfied. 

While FDR analysis identifies marginally significant words, there are some disadvantages of the analysis. The assumption of independence between tests from the FDR theory may not hold true for words in reviews, potentially leading to the inclusion of words with high semantic similarity. Additionally, analyzing words in isolation can result in a loss of contextual information, which can sometimes yield misleading outcomes. 
